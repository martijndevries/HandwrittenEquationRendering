{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6fab769-7359-4a8a-bd3f-0f2ff464231c",
   "metadata": {},
   "source": [
    "# EfficientNet CNN\n",
    "\n",
    "Notebook by Martijn de Vries <br>\n",
    "martijndevries91@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbb251d-5b88-4f2a-ab17-c62a89ce4559",
   "metadata": {},
   "source": [
    "NOTE: the EfficientNetB0 model that I use in this notebook has trouble saving with some version of tensorflow (probably 2.10 and higher) <br>\n",
    "I used the following fix to make it work on my machine (found in the comments here: https://github.com/keras-team/keras/issues/17199):\n",
    "\n",
    "location: lib/python3.10/site-packages/keras/applications/efficientnet.py (py3.10) <br>\n",
    "EDIT this: <br>\n",
    "<code> x = layers.Rescaling(1.0 / tf.math.sqrt(IMAGENET_STDDEV_RGB))(x) </code> <br>\n",
    "TO: <br>\n",
    "<code> x = layers.Rescaling(\n",
    "    [1.0 / math.sqrt(stddev) for stddev in IMAGENET_STDDEV_RGB]\n",
    ")(x) </code>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e447d2cd-c9aa-4237-a1b8-bafff7ed7028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-03 10:57:30.511871: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "#tensorflow\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img, smart_resize\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d14b2c3-3868-4164-be57-2dfc885520d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a360b6-1216-4c74-9741-53817ce1c27a",
   "metadata": {},
   "source": [
    "I can use image_dataset_from_directory to load in the images.\n",
    "Note that even though the images are grayscale, i have to use rgb color mode because that's the format EfficientNet requires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e41751b1-f19a-4bd4-9088-50d646458e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 93020 files belonging to 100 classes.\n",
      "Using 79067 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-03 10:57:38.870012: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 93020 files belonging to 100 classes.\n",
      "Using 13953 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = image_dataset_from_directory('../processed_images/', image_size=(100,100),\n",
    "                                      batch_size=200, seed=123, validation_split=0.15,\n",
    "                                       subset='training', labels ='inferred', color_mode='rgb', label_mode='categorical')  \n",
    "\n",
    "val_ds = image_dataset_from_directory('../processed_images/', image_size=(100,100),\n",
    "                                      batch_size=200, seed=123, validation_split=0.15,\n",
    "                                       subset='validation', labels ='inferred', color_mode='rgb', label_mode='categorical')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03739932-5475-47d4-92f0-e3a5278ffc66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_!', 'label_(', 'label_)', 'label_+', 'label_,']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.class_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e538f926-c23a-48c9-94b7-fc7238044ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the class names in a .txt file that I can use in the prediction notebook\n",
    "with open('../class_names.txt', 'w') as f:\n",
    "    for i, label in enumerate(train_ds.class_names):\n",
    "        f.write(str(i)+  ' ' + label + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18858742-b54d-4b01-87e7-8c0f9646eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(30):\n",
    "        img_list.append(images[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49053b1c-4992-46f3-9809-294971a4c149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd11ed8d130>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img_list[3][:], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8c966a2-2f01-4348-ba55-eee6f746d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df7b8990-e181-425f-9e7a-316f186be278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb0 (Functional)  (None, 1280)             4049571   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                40992     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               3300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,093,863\n",
      "Trainable params: 4,051,840\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "efficient_net = EfficientNetB0(\n",
    "    weights='imagenet',\n",
    "    input_shape=(100, 100, 3),\n",
    "    include_top=False,\n",
    "    pooling='max'\n",
    ")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(efficient_net)\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(units = 32, activation='relu'))\n",
    "model.add(Dense(units = 100, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate = 0.0005),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc6d7cb9-feb3-4ce1-a8e1-b24c41dfcbcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "396/396 [==============================] - 1311s 3s/step - loss: 0.8973 - accuracy: 0.8047 - val_loss: 0.3688 - val_accuracy: 0.9106\n",
      "Epoch 2/30\n",
      "396/396 [==============================] - 1269s 3s/step - loss: 0.2417 - accuracy: 0.9331 - val_loss: 0.2135 - val_accuracy: 0.9388\n",
      "Epoch 3/30\n",
      "396/396 [==============================] - 1252s 3s/step - loss: 0.1810 - accuracy: 0.9459 - val_loss: 0.2019 - val_accuracy: 0.9436\n",
      "Epoch 4/30\n",
      "396/396 [==============================] - 1238s 3s/step - loss: 0.1581 - accuracy: 0.9506 - val_loss: 0.2022 - val_accuracy: 0.9434\n",
      "Epoch 5/30\n",
      "396/396 [==============================] - 1238s 3s/step - loss: 0.1355 - accuracy: 0.9569 - val_loss: 0.1826 - val_accuracy: 0.9490\n",
      "Epoch 6/30\n",
      "396/396 [==============================] - 1247s 3s/step - loss: 0.1235 - accuracy: 0.9603 - val_loss: 0.1821 - val_accuracy: 0.9503\n",
      "Epoch 7/30\n",
      "396/396 [==============================] - 1247s 3s/step - loss: 0.1154 - accuracy: 0.9631 - val_loss: 0.1873 - val_accuracy: 0.9473\n",
      "Epoch 8/30\n",
      "396/396 [==============================] - 1249s 3s/step - loss: 0.1075 - accuracy: 0.9643 - val_loss: 0.1954 - val_accuracy: 0.9483\n",
      "Epoch 9/30\n",
      "396/396 [==============================] - 1244s 3s/step - loss: 0.0992 - accuracy: 0.9667 - val_loss: 0.1923 - val_accuracy: 0.9495\n",
      "Epoch 10/30\n",
      "396/396 [==============================] - 1244s 3s/step - loss: 0.0899 - accuracy: 0.9703 - val_loss: 0.1987 - val_accuracy: 0.9500\n",
      "Epoch 11/30\n",
      "396/396 [==============================] - 1244s 3s/step - loss: 0.0858 - accuracy: 0.9712 - val_loss: 0.1916 - val_accuracy: 0.9508\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(train_ds, validation_data=val_ds, epochs=30, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0ad0245-fde9-42c8-ab86-881229cd005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../CNN_model'\n",
    "if os.path.isdir(model_dir) == False: os.mkdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e74aed0-ae5d-4398-b5ad-a0ab0c3aa6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_dir + '/efficientnet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "897a65fd-8c45-4f6b-8952-aa81deeb2c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb0 (Functional)  (None, 1280)             4049571   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                40992     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               3300      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,093,863\n",
      "Trainable params: 4,051,840\n",
      "Non-trainable params: 42,023\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3dc348-1192-43b8-84bb-9a18bac6ce7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
